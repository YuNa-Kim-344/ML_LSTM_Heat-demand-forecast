{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd1ffe2f-d0ec-40b6-b629-e93cdfd44ea4",
   "metadata": {},
   "source": [
    "# 달리진점\n",
    "1. 데이터가 각 지사마다 시간순으로 이어져 있기때문에 지사와 지사의 경계에서도 시계열 데이터가 생기는 문제가 발생하여 지사별로 데이터프레임을 나눈후 각각 시계열 데이터화하여 다시 합침.\n",
    "2. 데이터셋을 학습용과 테스트용으로 나누기 전에 시계열 형태로 변환하게 되면, 생성된 train 독립변수와 test 독립변수 간에 시계열 특성상 일부 구간이 겹칠 수 있다. 이러한 중복은 모델의 테스트 성능을 과대평가하는 문제로 이어질 수 있다. 따라서 계절에 따라 큰 변동을 보이는 양상까지 고려하여, 모델의 일반화 성능을 더욱 정확히 평가하기 위해 2023년에 해당하는 데이터를 전체 테스트셋으로 분리하여 사용하였습니다. 반대로 2021년 2022년에 해당하는 데이터는 학습 데이터셋으로 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8dc5443-40b3-4e52-895e-9f528c9a3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35dd32c2-02df-4bf5-86c2-9f8ecc313d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021년 2022년은 학습 2023년은 테스트\n",
    "df = pd.read_csv('./final_heat.csv')\n",
    "le = LabelEncoder()\n",
    "df['branch_id'] = le.fit_transform(df['branch_id'])\n",
    "df['year'] = df['tm'].apply(lambda x : int(str(x)[:4]))\n",
    "\n",
    "# 2023년 데이터\n",
    "df_2023 = df[df['year'] == 2023].reset_index(drop=True).iloc[:,1:-1]\n",
    "\n",
    "# 2021년, 2022년 데이터\n",
    "df = df[df['year'] != 2023].iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54f49a9b-ba5f-451b-bdea-7baf8eb6c21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id</th>\n",
       "      <th>hm</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>ta_chi</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>heat_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68.2</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>69.2</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>63.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-9.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490536</th>\n",
       "      <td>18</td>\n",
       "      <td>61.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490537</th>\n",
       "      <td>18</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490538</th>\n",
       "      <td>18</td>\n",
       "      <td>75.8</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490539</th>\n",
       "      <td>18</td>\n",
       "      <td>76.9</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490540</th>\n",
       "      <td>18</td>\n",
       "      <td>79.4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.201299</td>\n",
       "      <td>0.97953</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332861 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        branch_id    hm  is_holiday  ta_chi  month_sin  month_cos  hour_sin  \\\n",
       "0               0  68.2           1    -8.2        0.0   1.000000  0.258819   \n",
       "1               0  69.9           1    -8.6        0.0   1.000000  0.500000   \n",
       "2               0  69.2           1    -8.8        0.0   1.000000  0.707107   \n",
       "3               0  65.0           1    -8.9        0.0   1.000000  0.866025   \n",
       "4               0  63.5           1    -9.2        0.0   1.000000  0.965926   \n",
       "...           ...   ...         ...     ...        ...        ...       ...   \n",
       "490536         18  61.1           1    -0.1       -0.5   0.866025 -0.965926   \n",
       "490537         18  68.5           1    -1.4       -0.5   0.866025 -0.866025   \n",
       "490538         18  75.8           1    -2.2       -0.5   0.866025 -0.707107   \n",
       "490539         18  76.9           1    -2.7       -0.5   0.866025 -0.500000   \n",
       "490540         18  79.4           1    -3.2       -0.5   0.866025 -0.258819   \n",
       "\n",
       "        hour_cos   day_sin  day_cos  heat_demand  \n",
       "0       0.965926  0.000000  1.00000        281.0  \n",
       "1       0.866025  0.000000  1.00000        262.0  \n",
       "2       0.707107  0.000000  1.00000        266.0  \n",
       "3       0.500000  0.000000  1.00000        285.0  \n",
       "4       0.258819  0.000000  1.00000        283.0  \n",
       "...          ...       ...      ...          ...  \n",
       "490536  0.258819 -0.201299  0.97953         29.0  \n",
       "490537  0.500000 -0.201299  0.97953         30.0  \n",
       "490538  0.707107 -0.201299  0.97953         30.0  \n",
       "490539  0.866025 -0.201299  0.97953         32.0  \n",
       "490540  0.965926 -0.201299  0.97953         30.0  \n",
       "\n",
       "[332861 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23ef4764-6d2f-46cf-8a43-7df30c7ade64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터셋 생성 함수\n",
    "def create_dataset(data, time_step=48):    \n",
    "    x_ = []  \n",
    "    y_ = []\n",
    "    b_id = []\n",
    "    # 실습 ppt에 있는 시계열 데이터화 하는 함수는 대용량 데이터프레임(메타데이터 포함)은 너무 무겁고 오래 걸리지만\n",
    "    # 데이터프레임을 넘파이 배열로 바꾸고 계산하면 훨씬 빠르고 가볍다.\n",
    "    for i in range(len(data) - time_step - 1):        \n",
    "        x = data[i:(i + time_step), 1:] # x에 정답 포함여부 설정하기\n",
    "        y = data[(i + time_step), -1]\n",
    "        b = data[i:(i + time_step), 0] \n",
    "        if np.isnan(x).any() or np.isnan(y).any():\n",
    "            continue\n",
    "        else :\n",
    "            x_.append(x)\n",
    "            y_.append(y)\n",
    "            b_id.append(b)\n",
    "    return np.array(x_), np.array(y_), np.array(b_id)\n",
    "\n",
    "# 지사별로 데이터 나눈후 create_dataset으로 지사별로 시계열 데이터셋 생성하고 지사별로 나눴던거 다시 concat하는 함수\n",
    "def split_x_y_bid(data):\n",
    "    X_all = []\n",
    "    Y_all = []\n",
    "    B_all = []\n",
    "\n",
    "    for i in range(len(data['branch_id'].unique())):\n",
    "        globals()[\"df_\"+str(i)] = data[data['branch_id'] == i ]\n",
    "        print(f\"df_{i}  : \", globals()[f\"df_{i}\"].shape[0],\"개\")\n",
    "        X, Y, B_id = create_dataset(globals()[f\"df_{i}\"].values, time_step=48) # 24시간 단위로 자른다. -> 48시간전 데이터\n",
    "        X_all.append(X)\n",
    "        Y_all.append(Y)\n",
    "        B_all.append(B_id)\n",
    "        print(\" 완료\\n\")\n",
    "    \n",
    "    X = np.concatenate(X_all, axis=0) # 넘파이 배열 concat\n",
    "    Y = np.concatenate(Y_all, axis=0)\n",
    "    B_id = np.concatenate(B_all, axis=0)\n",
    "    return X, Y, B_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0aa235c6-4aef-49d0-b454-61fd66c46fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_0  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_1  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_2  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_3  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_4  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_5  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_6  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_7  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_8  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_9  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_10  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_11  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_12  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_13  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_14  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_15  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_16  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_17  :  8760 개\n",
      " 완료\n",
      "\n",
      "df_18  :  8760 개\n",
      " 완료\n",
      "\n",
      "결측치 수 0\n",
      "X_2023 shape :  (158111, 48, 10)\n",
      "Y_2023 shape :  (158111,)\n",
      "B_id_2023 shape :  (158111, 48)\n"
     ]
    }
   ],
   "source": [
    "# 2023년 데이터셋 생성\n",
    "x_test, y_test, b_test = split_x_y_bid(df_2023)\n",
    "\n",
    "print(\"결측치 수\", np.isnan(x_test).sum() + np.isnan(y_test).sum() + np.isnan(b_test).sum())\n",
    "print(\"X_2023 shape : \", x_test.shape)\n",
    "print(\"Y_2023 shape : \", y_test.shape)\n",
    "print(\"B_id_2023 shape : \", b_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74845eff-616d-4bf3-a23d-e0ad3e9c6579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_0  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_1  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_2  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_3  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_4  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_5  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_6  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_7  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_8  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_9  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_10  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_11  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_12  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_13  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_14  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_15  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_16  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_17  :  17519 개\n",
      " 완료\n",
      "\n",
      "df_18  :  17519 개\n",
      " 완료\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m y_train \u001b[38;5;241m=\u001b[39m Y[indices]\n\u001b[1;32m      7\u001b[0m b_train \u001b[38;5;241m=\u001b[39m B_id[indices]\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m결측치 수\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39misnan(X_train)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(\u001b[43mY_train\u001b[49m)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(B_train)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX shape : \u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY shape : \u001b[39m\u001b[38;5;124m\"\u001b[39m, Y_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 2021년,2022년 데이터셋 생성 및 데이터 섞기\n",
    "X, Y, B_id = split_x_y_bid(df)\n",
    "rng = np.random.default_rng(seed=1)  # 난수 생성기 객체 생성\n",
    "indices = rng.permutation(len(x)) # 무작위 배열 생성\n",
    "x_train = X[indices]\n",
    "y_train = Y[indices]\n",
    "b_train = B_id[indices]\n",
    "\n",
    "print(\"결측치 수\", np.isnan(X_train).sum() + np.isnan(Y_train).sum() + np.isnan(B_train).sum())\n",
    "print(\"X shape : \", X_train.shape)\n",
    "print(\"Y shape : \", Y_train.shape)\n",
    "print(\"B_id shape : \", B_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f302610-165d-4955-a1d6-7346e8795e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 12:07:36,015] A new study created in memory with name: no-name-cd0683b4-9f7b-49c1-b935-468142a584bb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc8e24d2b5e46f085c6639f8cd92ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units_1 : 128, units_2 : 256, batch_size : 256\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "[I 2025-06-17 12:20:04,627] Trial 0 finished with value: 64.05445384979248 and parameters: {'units_1': 128, 'units_2': 256, 'batch_size': 256}. Best is trial 0 with value: 64.05445384979248.\n",
      "units_1 : 128, units_2 : 256, batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 43: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "[I 2025-06-17 12:30:05,853] Trial 1 finished with value: 62.85215187072754 and parameters: {'units_1': 128, 'units_2': 256, 'batch_size': 512}. Best is trial 1 with value: 62.85215187072754.\n",
      "units_1 : 256, units_2 : 256, batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 88: early stopping\n",
      "Restoring model weights from the end of the best epoch: 78.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 75: early stopping\n",
      "Restoring model weights from the end of the best epoch: 65.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "[I 2025-06-17 12:49:46,549] Trial 2 finished with value: 58.0773229598999 and parameters: {'units_1': 256, 'units_2': 256, 'batch_size': 512}. Best is trial 2 with value: 58.0773229598999.\n",
      "units_1 : 128, units_2 : 256, batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 41: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "[I 2025-06-17 13:02:03,222] Trial 3 finished with value: 60.515289306640625 and parameters: {'units_1': 128, 'units_2': 256, 'batch_size': 512}. Best is trial 2 with value: 58.0773229598999.\n",
      "units_1 : 128, units_2 : 256, batch_size : 256\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 80: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 52: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "[I 2025-06-17 13:20:42,510] Trial 4 finished with value: 60.056870460510254 and parameters: {'units_1': 128, 'units_2': 256, 'batch_size': 256}. Best is trial 2 with value: 58.0773229598999.\n",
      "units_1 : 128, units_2 : 256, batch_size : 256\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "[I 2025-06-17 13:37:01,259] Trial 5 finished with value: 61.042245864868164 and parameters: {'units_1': 128, 'units_2': 256, 'batch_size': 256}. Best is trial 2 with value: 58.0773229598999.\n",
      "units_1 : 128, units_2 : 128, batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 68: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 58: early stopping\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 94: early stopping\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "[I 2025-06-17 13:48:22,814] Trial 6 finished with value: 58.25312519073486 and parameters: {'units_1': 128, 'units_2': 128, 'batch_size': 512}. Best is trial 2 with value: 58.0773229598999.\n",
      "units_1 : 256, units_2 : 128, batch_size : 256\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "[I 2025-06-17 14:04:40,827] Trial 7 finished with value: 61.41714859008789 and parameters: {'units_1': 256, 'units_2': 128, 'batch_size': 256}. Best is trial 2 with value: 58.0773229598999.\n",
      "Best trial :  {'units_1': 256, 'units_2': 256, 'batch_size': 512}\n",
      "Best loss :  [58.0773229598999]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import optuna\n",
    "\n",
    "# 모델 하이퍼 파라미터 튜닝\n",
    "def build_model(units_1, units_2):\n",
    "    seq_input = Input(shape=(X.shape[1], X.shape[2]), name='sequence_input')\n",
    "    branch_input = Input(shape=(B_id.shape[1],), name='branch_id_input') \n",
    "    branch_embed = Embedding(input_dim=19, output_dim=4)(branch_input)\n",
    "    merged = Concatenate(axis=-1)([seq_input, branch_embed])\n",
    "    \n",
    "    x = LSTM(units_1, return_sequences=True)(merged)\n",
    "    x = LSTM(units_2, return_sequences=False)(x)\n",
    "    final_output = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=[seq_input, branch_input], outputs=final_output, name='lstm')\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    units_1 = trial.suggest_categorical('units_1', [128, 256])\n",
    "    units_2 = trial.suggest_categorical('units_2', [128, 256])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [256, 512])\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=1)\n",
    "    val_losses = []\n",
    "    print(f\"units_1 : {units_1}, units_2 : {units_2}, batch_size : {batch_size}\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\n===== Fold {fold + 1} =====\")\n",
    "        b_train, b_val = B_id[train_idx] , B_id[val_idx]\n",
    "        x_train, x_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = Y[train_idx], Y[val_idx]\n",
    "\n",
    "        model = build_model(units_1, units_2)\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "        history = model.fit(\n",
    "            [x_train, b_train], y_train,\n",
    "            validation_data=([x_val, b_val], y_val),\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es],\n",
    "            verbose=0\n",
    "        )\n",
    "        val_losses.append(min(history.history['val_loss']))\n",
    "\n",
    "    return np.mean(val_losses)\n",
    "\n",
    "# Optuna 실행\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=8, show_progress_bar = True)\n",
    "\n",
    "print(\"Best trial : \", study.best_trial.params)\n",
    "print(\"Best loss : \", study.best_trial.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3baf145d-7723-4e02-a196-a6c4cf849cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "units_1 = study.best_trial.params.get('units_1')\n",
    "units_2 = study.best_trial.params.get('units_2')\n",
    "batch_size = study.best_trial.params.get('batch_size')\n",
    "\n",
    "# Best trial :  {'units_1': 256, 'units_2': 256, 'batch_size': 512}\n",
    "# Best loss :  [58.0773229598999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "565a13b5-4656-4123-8a71-2e989f828f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"lstm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ branch_id_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequence_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_57        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span> │ branch_id_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_57      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ embedding_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">277,504</span> │ concatenate_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ lstm_114[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ lstm_115[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ branch_id_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequence_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_57        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │         \u001b[38;5;34m76\u001b[0m │ branch_id_input[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_57      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m14\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ sequence_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ embedding_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_114 (\u001b[38;5;33mLSTM\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m277,504\u001b[0m │ concatenate_57[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_115 (\u001b[38;5;33mLSTM\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m525,312\u001b[0m │ lstm_114[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ lstm_115[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">803,149</span> (3.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m803,149\u001b[0m (3.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">803,149</span> (3.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m803,149\u001b[0m (3.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# (batch, time_steps, features)\n",
    "seq_input = Input(shape=(X.shape[1], X.shape[2]), name='sequence_input')\n",
    "# (batch, time_steps)\n",
    "branch_input = Input(shape=(B_id.shape[1],), name='branch_id_input')  \n",
    "# (batch, time_steps, 4)\n",
    "branch_embed = Embedding(input_dim=19, output_dim=4)(branch_input)\n",
    "\n",
    "# (batch, time_steps, features + 4)\n",
    "merged = Concatenate(axis=-1)([seq_input, branch_embed])\n",
    "x = LSTM(units_1, return_sequences=True)(merged)\n",
    "x = LSTM(units_2, return_sequences=False)(x)\n",
    "final_output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[seq_input, branch_input], outputs=final_output, name='lstm')\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2bcfd1ea-b02f-4e12-ab81-399d9403df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val shape :  (126488, 48, 10)\n",
      "x_test shape :  (31623, 48, 10)\n",
      "y_val shape :  (126488,)\n",
      "y_test shape :  (31623,)\n",
      "b_val shape :  (126488, 48)\n",
      "b_test shape :  (31623, 48)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_val, x_test, y_val, y_test, b_val, b_test = train_test_split(x_test, y_test, b_test, test_size = 0.2, random_state = 1)\n",
    "\n",
    "print(\"x_val shape : \", x_val.shape)\n",
    "print(\"x_test shape : \", x_test.shape)\n",
    "print(\"y_val shape : \", y_val.shape)\n",
    "print(\"y_test shape : \", y_test.shape)\n",
    "print(\"b_val shape : \", b_val.shape)\n",
    "print(\"b_test shape : \", b_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "858d19c9-7d91-4ed8-9a6b-7d617447ad0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 15866.0303 - val_loss: 6822.6904\n",
      "Epoch 2/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 7222.6729 - val_loss: 3581.4749\n",
      "Epoch 3/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 4102.9082 - val_loss: 2010.5728\n",
      "Epoch 4/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 2384.8394 - val_loss: 1167.9502\n",
      "Epoch 5/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 1556.1556 - val_loss: 702.1907\n",
      "Epoch 6/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 979.7728 - val_loss: 454.7315\n",
      "Epoch 7/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 624.4266 - val_loss: 295.7190\n",
      "Epoch 8/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 431.9833 - val_loss: 207.9751\n",
      "Epoch 9/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 297.2740 - val_loss: 152.1541\n",
      "Epoch 10/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 213.5227 - val_loss: 126.2532\n",
      "Epoch 11/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 168.4245 - val_loss: 109.3080\n",
      "Epoch 12/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 135.7294 - val_loss: 93.8214\n",
      "Epoch 13/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 111.5410 - val_loss: 81.6326\n",
      "Epoch 14/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 98.1265 - val_loss: 80.5177\n",
      "Epoch 15/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 90.5333 - val_loss: 80.1238\n",
      "Epoch 16/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 84.4643 - val_loss: 72.8689\n",
      "Epoch 17/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 78.7515 - val_loss: 73.6692\n",
      "Epoch 18/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 77.4370 - val_loss: 71.1131\n",
      "Epoch 19/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 71.8536 - val_loss: 67.1469\n",
      "Epoch 20/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 69.9086 - val_loss: 67.2201\n",
      "Epoch 21/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 68.8038 - val_loss: 63.3351\n",
      "Epoch 22/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 67.1113 - val_loss: 64.4239\n",
      "Epoch 23/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 66.7562 - val_loss: 63.2952\n",
      "Epoch 24/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 64.9892 - val_loss: 63.7512\n",
      "Epoch 25/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 65.9561 - val_loss: 67.9921\n",
      "Epoch 26/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 66.8656 - val_loss: 67.2213\n",
      "Epoch 27/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 65.2969 - val_loss: 63.2384\n",
      "Epoch 28/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 63.3446 - val_loss: 67.5761\n",
      "Epoch 29/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 65.0040 - val_loss: 62.9241\n",
      "Epoch 30/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 65.7938 - val_loss: 62.3658\n",
      "Epoch 31/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 61.4481 - val_loss: 66.3657\n",
      "Epoch 32/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 63.3880 - val_loss: 63.4296\n",
      "Epoch 33/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 64.4532 - val_loss: 64.8522\n",
      "Epoch 34/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 62.7900 - val_loss: 64.6269\n",
      "Epoch 35/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 61.3652 - val_loss: 67.6989\n",
      "Epoch 36/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 65.0353 - val_loss: 64.8654\n",
      "Epoch 37/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 61.5774 - val_loss: 65.8917\n",
      "Epoch 38/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 62.4984 - val_loss: 60.3580\n",
      "Epoch 39/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 60.2287 - val_loss: 61.3772\n",
      "Epoch 40/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 60.8921 - val_loss: 68.7703\n",
      "Epoch 41/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 61.1840 - val_loss: 70.8295\n",
      "Epoch 42/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 63.1274 - val_loss: 62.6890\n",
      "Epoch 43/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 59.9562 - val_loss: 62.1662\n",
      "Epoch 44/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 59.1431 - val_loss: 63.7058\n",
      "Epoch 45/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 59.4994 - val_loss: 66.9547\n",
      "Epoch 46/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 59.4524 - val_loss: 69.5135\n",
      "Epoch 47/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 58.7297 - val_loss: 65.6758\n",
      "Epoch 48/100\n",
      "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 58.8854 - val_loss: 70.0161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f0d93367bd0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping( monitor=\"val_loss\", patience = 10, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    [x_train, b_train], y_train,\n",
    "    validation_data=([x_val, b_val], y_val),\n",
    "    epochs=100,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c455ad6a-9fd3-47fd-958c-ada5ff274bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "R2 :  0.9950061846046331\n",
      "Adjusted R2 :  0.9949985928158519 \n",
      "\n",
      "MSE :  60.92172868965152\n",
      "RMSE :  7.805237260304874\n",
      "MAE :  4.535790074132853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "def adj_r2_score(y_test, pred, p=X.shape[1]):\n",
    "    return 1-(1-r2_score(y_test, pred)) * (len(y_test)-1) / (len(y_test) - p - 1)\n",
    "\n",
    "pred = model.predict([x_test, b_test])    \n",
    "ad_r2 = adj_r2_score(y_test, pred)\n",
    "mse = mean_squared_error(y_test.reshape(-1,1), pred)\n",
    "mae = mean_absolute_error(y_test.reshape(-1,1), pred)\n",
    "r2 = r2_score(y_test.reshape(-1,1), pred)\n",
    "\n",
    "print(\"R2 : \", r2)\n",
    "print(\"Adjusted R2 : \", ad_r2, '\\n')\n",
    "print(\"MSE : \", mse)\n",
    "print(\"RMSE : \", np.sqrt(mse))\n",
    "print(\"MAE : \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb10e60c-15df-43ee-af86-4f6951bb60a7",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08f0cdab-c632-4a69-8391-2dbd5156cd10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-17 15:05:37,266] A new study created in memory with name: no-name-5bf774a3-1311-4a67-96f1-8541968cc7ed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ab5d37fe64414bac1e958f9e1f8d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gru_units_1 : 256, units_2 : 256, gru_batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 47: early stopping\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "[I 2025-06-17 15:19:40,960] Trial 0 finished with value: 64.79286193847656 and parameters: {'gru_units_1': 256, 'gru_units_2': 256, 'gru_batch_size': 512}. Best is trial 0 with value: 64.79286193847656.\n",
      "gru_units_1 : 128, units_2 : 256, gru_batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 81: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "[I 2025-06-17 15:32:09,141] Trial 1 finished with value: 62.26547718048096 and parameters: {'gru_units_1': 128, 'gru_units_2': 256, 'gru_batch_size': 512}. Best is trial 1 with value: 62.26547718048096.\n",
      "gru_units_1 : 128, units_2 : 256, gru_batch_size : 256\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 89: early stopping\n",
      "Restoring model weights from the end of the best epoch: 79.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 55.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 53: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n",
      "[I 2025-06-17 15:44:42,064] Trial 2 finished with value: 62.04658222198486 and parameters: {'gru_units_1': 128, 'gru_units_2': 256, 'gru_batch_size': 256}. Best is trial 2 with value: 62.04658222198486.\n",
      "gru_units_1 : 256, units_2 : 128, gru_batch_size : 256\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 59: early stopping\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 56: early stopping\n",
      "Restoring model weights from the end of the best epoch: 46.\n",
      "[I 2025-06-17 15:57:09,658] Trial 3 finished with value: 65.04956722259521 and parameters: {'gru_units_1': 256, 'gru_units_2': 128, 'gru_batch_size': 256}. Best is trial 2 with value: 62.04658222198486.\n",
      "gru_units_1 : 256, units_2 : 256, gru_batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 70: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 67.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n",
      "[I 2025-06-17 16:12:26,976] Trial 4 finished with value: 63.6312198638916 and parameters: {'gru_units_1': 256, 'gru_units_2': 256, 'gru_batch_size': 512}. Best is trial 2 with value: 62.04658222198486.\n",
      "gru_units_1 : 128, units_2 : 128, gru_batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 60: early stopping\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 57: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 98: early stopping\n",
      "Restoring model weights from the end of the best epoch: 88.\n",
      "[I 2025-06-17 16:22:40,258] Trial 5 finished with value: 64.15276622772217 and parameters: {'gru_units_1': 128, 'gru_units_2': 128, 'gru_batch_size': 512}. Best is trial 2 with value: 62.04658222198486.\n",
      "gru_units_1 : 128, units_2 : 128, gru_batch_size : 256\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 66.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 63.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 71: early stopping\n",
      "Restoring model weights from the end of the best epoch: 61.\n",
      "[I 2025-06-17 16:33:38,105] Trial 6 finished with value: 62.1820182800293 and parameters: {'gru_units_1': 128, 'gru_units_2': 128, 'gru_batch_size': 256}. Best is trial 2 with value: 62.04658222198486.\n",
      "gru_units_1 : 128, units_2 : 128, gru_batch_size : 512\n",
      "\n",
      "===== Fold 1 =====\n",
      "Epoch 66: early stopping\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "\n",
      "===== Fold 2 =====\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n",
      "\n",
      "===== Fold 3 =====\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "\n",
      "===== Fold 4 =====\n",
      "Epoch 61: early stopping\n",
      "Restoring model weights from the end of the best epoch: 51.\n",
      "[I 2025-06-17 16:43:46,141] Trial 7 finished with value: 63.605857849121094 and parameters: {'gru_units_1': 128, 'gru_units_2': 128, 'gru_batch_size': 512}. Best is trial 2 with value: 62.04658222198486.\n",
      "Best trial :  {'units_1': 256, 'units_2': 256, 'batch_size': 512}\n",
      "Best loss :  [58.0773229598999]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Embedding, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import optuna\n",
    "\n",
    "# 모델 하이퍼 파라미터 튜닝\n",
    "def build_model(gru_units_1, gru_units_2):\n",
    "    seq_input = Input(shape=(X.shape[1], X.shape[2]), name='sequence_input')\n",
    "    branch_input = Input(shape=(B_id.shape[1],), name='branch_id_input') \n",
    "    branch_embed = Embedding(input_dim=19, output_dim=4)(branch_input)\n",
    "    merged = Concatenate(axis=-1)([seq_input, branch_embed])\n",
    "    \n",
    "    x = GRU(gru_units_1, return_sequences=True)(merged)\n",
    "    x = GRU(gru_units_2, return_sequences=False)(x)\n",
    "    final_output = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=[seq_input, branch_input], outputs=final_output, name='lstm')\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    gru_units_1 = trial.suggest_categorical('gru_units_1', [128, 256])\n",
    "    gru_units_2 = trial.suggest_categorical('gru_units_2', [128, 256])\n",
    "    gru_batch_size = trial.suggest_categorical('gru_batch_size', [256, 512])\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=1)\n",
    "    val_losses = []\n",
    "    print(f\"gru_units_1 : {gru_units_1}, units_2 : {gru_units_2}, gru_batch_size : {gru_batch_size}\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\n===== Fold {fold + 1} =====\")\n",
    "        b_train, b_val = B_id[train_idx] , B_id[val_idx]\n",
    "        x_train, x_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = Y[train_idx], Y[val_idx]\n",
    "\n",
    "        model = build_model(gru_units_1, gru_units_2)\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "        history = model.fit(\n",
    "            [x_train, b_train], y_train,\n",
    "            validation_data=([x_val, b_val], y_val),\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es],\n",
    "            verbose=0\n",
    "        )\n",
    "        val_losses.append(min(history.history['val_loss']))\n",
    "\n",
    "    return np.mean(val_losses)\n",
    "\n",
    "# Optuna 실행\n",
    "gru_study = optuna.create_study(direction='minimize')\n",
    "gru_study.optimize(objective, n_trials=8, show_progress_bar = True)\n",
    "\n",
    "print(\"Best trial : \", gru_study.best_trial.params)\n",
    "print(\"Best loss : \", gru_study.best_trial.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4a0bc0bb-1007-41a4-aef3-9ca048390932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial :  {'gru_units_1': 128, 'gru_units_2': 256, 'gru_batch_size': 256}\n",
      "Best loss :  [62.04658222198486]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial : \", gru_study.best_trial.params)\n",
    "print(\"Best loss : \", gru_study.best_trial.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4420e32f-bc0e-4689-92d9-65d346430edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_units_1 = gru_study.best_trial.params.get('gru_units_1')\n",
    "gru_units_2 = gru_study.best_trial.params.get('gru_units_2')\n",
    "gru_batch_size = gru_study.best_trial.params.get('gru_batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1d0ec0ee-898d-4761-aea8-f1c0ba23141e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gru\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gru\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ branch_id_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequence_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_104       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span> │ branch_id_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_104     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ embedding_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">55,296</span> │ concatenate_104[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> │ gru_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ gru_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ branch_id_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequence_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_104       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │         \u001b[38;5;34m76\u001b[0m │ branch_id_input[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_104     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m14\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ sequence_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ embedding_104[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_84 (\u001b[38;5;33mGRU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m55,296\u001b[0m │ concatenate_104[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gru_85 (\u001b[38;5;33mGRU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m296,448\u001b[0m │ gru_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ gru_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352,077</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m352,077\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352,077</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m352,077\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "seq_input = Input(shape=(X.shape[1], X.shape[2]), name='sequence_input')  \n",
    "branch_input = Input(shape=(B_id.shape[1],), name='branch_id_input')      \n",
    "branch_embed = Embedding(input_dim=19, output_dim=4)(branch_input)        \n",
    "\n",
    "merged = Concatenate(axis=-1)([seq_input, branch_embed])                 \n",
    "x = GRU(gru_units_1, return_sequences=True)(merged)\n",
    "x = GRU(gru_units_2, return_sequences=False)(x)\n",
    "final_output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[seq_input, branch_input], outputs=final_output, name='gru')\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "624845ab-7a9b-460f-993e-04da27e92d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - loss: 13542.6064 - val_loss: 3626.6848\n",
      "Epoch 2/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 3723.8247 - val_loss: 1194.5446\n",
      "Epoch 3/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1390.0104 - val_loss: 450.5083\n",
      "Epoch 4/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 591.1649 - val_loss: 220.3590\n",
      "Epoch 5/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 283.4827 - val_loss: 143.3211\n",
      "Epoch 6/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 169.7278 - val_loss: 97.8200\n",
      "Epoch 7/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 119.8439 - val_loss: 92.9501\n",
      "Epoch 8/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 100.8282 - val_loss: 79.9255\n",
      "Epoch 9/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 94.3470 - val_loss: 76.2921\n",
      "Epoch 10/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 86.4268 - val_loss: 74.4917\n",
      "Epoch 11/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 85.2477 - val_loss: 97.9112\n",
      "Epoch 12/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 82.5911 - val_loss: 82.9388\n",
      "Epoch 13/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 83.0570 - val_loss: 75.0722\n",
      "Epoch 14/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 82.3071 - val_loss: 74.7034\n",
      "Epoch 15/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 79.7384 - val_loss: 71.3949\n",
      "Epoch 16/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 79.0397 - val_loss: 76.9245\n",
      "Epoch 17/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 79.6578 - val_loss: 71.9301\n",
      "Epoch 18/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 77.1256 - val_loss: 80.2508\n",
      "Epoch 19/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 80.4820 - val_loss: 73.6532\n",
      "Epoch 20/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 77.9459 - val_loss: 72.0457\n",
      "Epoch 21/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 78.2580 - val_loss: 73.3951\n",
      "Epoch 22/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 75.8870 - val_loss: 74.6190\n",
      "Epoch 23/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 75.9884 - val_loss: 75.3454\n",
      "Epoch 24/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 76.6576 - val_loss: 73.1205\n",
      "Epoch 25/100\n",
      "\u001b[1m1128/1128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 77.4052 - val_loss: 74.2238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f0e2f7436d0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping( monitor=\"val_loss\", patience = 10, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    [x_train, b_train], y_train,\n",
    "    validation_data=([x_val, b_val], y_val),\n",
    "    epochs=100,\n",
    "    batch_size=gru_batch_size,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "98012e2c-ada6-4f46-81a9-77a8dca76d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "R2 :  0.993922872068303\n",
      "Adjusted R2 :  0.9939136333864533 \n",
      "\n",
      "MSE :  74.13753007582797\n",
      "RMSE :  8.610315329639674\n",
      "MAE :  4.986189179299388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "def adj_r2_score(y_test, pred, p=X.shape[1]):\n",
    "    return 1-(1-r2_score(y_test, pred)) * (len(y_test)-1) / (len(y_test) - p - 1)\n",
    "\n",
    "pred = model.predict([x_test, b_test])    \n",
    "ad_r2 = adj_r2_score(y_test, pred)\n",
    "mse = mean_squared_error(y_test.reshape(-1,1), pred)\n",
    "mae = mean_absolute_error(y_test.reshape(-1,1), pred)\n",
    "r2 = r2_score(y_test.reshape(-1,1), pred)\n",
    "\n",
    "print(\"R2 : \", r2)\n",
    "print(\"Adjusted R2 : \", ad_r2, '\\n')\n",
    "print(\"MSE : \", mse)\n",
    "print(\"RMSE : \", np.sqrt(mse))\n",
    "print(\"MAE : \", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83cb106-0a88-4883-af3e-ebe042a1588b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 신경망 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26d7f51b-5bbd-455c-8973-c93346b0a687",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./final_heat.csv')\n",
    "le = LabelEncoder()\n",
    "df['branch_id'] = le.fit_transform(df['branch_id'])\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df['year'] = df['tm'].apply(lambda x : int(str(x)[:4]))\n",
    "\n",
    "df_val = df[df['year']==2023].reset_index(drop=True)\n",
    "df_train = df[df['year']!=2023]\n",
    "\n",
    "# 상관관계 높은 변수\n",
    "df_train = df_train[['branch_id', 'is_holiday', 'hm', 'ta_chi', 'month_poly', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'heat_demand']]\n",
    "df_val = df_val[['branch_id', 'is_holiday', 'hm', 'ta_chi', 'month_poly', 'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'heat_demand']]\n",
    "\n",
    "# 기본변수\n",
    "# df_train = df_train[['branch_id', 'is_holiday', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1',\n",
    "#                      'hm', 'ta_chi', 'month_poly', 'hour_sin', 'hour_cos', 'day_sin',\n",
    "#                      'day_cos', 'heat_demand']]\n",
    "# df_val = df_val[['branch_id', 'is_holiday', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1',\n",
    "#                      'hm', 'ta_chi', 'month_poly', 'hour_sin', 'hour_cos', 'day_sin',\n",
    "#                      'day_cos', 'heat_demand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77a15446-f487-4515-8842-c023f1fe35c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "x_train = df_train.iloc[:,1:-1]\n",
    "y_train = df_train.iloc[:,-1]\n",
    "b_train = df_train[['branch_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7d55d60-e2f8-46b2-8136-beaf7b76e1de",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_val_x = df_val.iloc[:,1:-1]\n",
    "df_val_y = df_val.iloc[:,-1]\n",
    "df_val_bid = df_val[['branch_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6fffb47-ee90-4542-a485-63dd722730d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149582, 8)\n",
      "(149582,)\n",
      "(7873, 8)\n",
      "(7873,)\n"
     ]
    }
   ],
   "source": [
    "x_val, x_test, y_val, y_test, b_val, b_test = train_test_split(df_val_x, df_val_y, df_val_bid, test_size = 0.05)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b62b38b8-9085-4e03-863f-06b5e9da8b93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ss_x = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "# 상관관계 높은 변수\n",
    "feature = [\"hm\", \"ta_chi\", \"month_poly\"]\n",
    "# 기본변수\n",
    "# feature = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'ta_chi', 'month_poly']\n",
    "\n",
    "\n",
    "x_train[feature] = ss_x.fit_transform(x_train[feature])\n",
    "x_val[feature] = ss_x.transform(x_val[feature])\n",
    "x_test[feature] = ss_x.transform(x_test[feature])\n",
    "\n",
    "y_train = ss_y.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "y_val = ss_y.transform(np.array(y_val).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e286a8f-22e5-405c-9722-b09ec4fb5a3e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trian shape :  (290069, 8)\n",
      "Y_trian shape :  (290069, 1)\n",
      "X_val shape :  (149582, 8)\n",
      "Y_val shape :  (149582, 1)\n",
      "X_test shape :  (7873, 8)\n",
      "Y_test shape :  (7873,)\n",
      "B_train shape :  (290069, 1)\n",
      "B_val shape :  (149582, 1)\n",
      "B_test shape :  (7873, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_trian shape : \", x_train.shape)\n",
    "print(\"Y_trian shape : \", y_train.shape)\n",
    "\n",
    "print(\"X_val shape : \", x_val.shape)\n",
    "print(\"Y_val shape : \", y_val.shape)\n",
    "\n",
    "print(\"X_test shape : \", x_test.shape)\n",
    "print(\"Y_test shape : \", y_test.shape)\n",
    "\n",
    "print(\"B_train shape : \", b_train.shape)\n",
    "print(\"B_val shape : \", b_val.shape)\n",
    "print(\"B_test shape : \", b_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b331dc7-156b-48f5-96e3-f447053e9086",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 4)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c371fc80-2fb8-40b6-9c4a-81b7f712e04a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MLP\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MLP\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ branch_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_21        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span> │ branch_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_21      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │ concatenate_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_32      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ leaky_re_lu_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_33      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ leaky_re_lu_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ branch_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_21        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │         \u001b[38;5;34m76\u001b[0m │ branch_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_21      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m1,664\u001b[0m │ concatenate_21[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_32      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ leaky_re_lu_32[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dense_53[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_33      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ leaky_re_lu_33[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,405</span> (75.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,405\u001b[0m (75.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,893</span> (73.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,893\u001b[0m (73.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, Flatten, Concatenate, BatchNormalization, LeakyReLU\n",
    "\n",
    "input_ = Input(shape=(x_train.shape[1],), name='input')\n",
    "\n",
    "branch_input = Input(shape=(1,), name='branch_input')  # (batch_size, 1)\n",
    "branch_embed = Embedding(input_dim=19, output_dim=4)(branch_input)  # 19개 지사, 임베딩 차원 4\n",
    "branch_embed = Flatten()(branch_embed)  # (batch_size, 4)\n",
    "\n",
    "merged = Concatenate()([input_, branch_embed])\n",
    "\n",
    "x = Dense(128, kernel_initializer=\"he_normal\")(merged)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(negative_slope=0.1)(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "\n",
    "x = Dense(128, kernel_initializer=\"he_normal\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(negative_slope=0.1)(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "\n",
    "# x = Dense(128, kernel_initializer=\"he_normal\")(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = LeakyReLU(negative_slope=0.1)(x)\n",
    "\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=[input_, branch_input], outputs=output, name='MLP')\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f6901fc-d60a-420e-845e-9c38648bd6b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2713 - val_loss: 0.0485\n",
      "Epoch 2/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 0.0394 - val_loss: 0.0380\n",
      "Epoch 3/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0332 - val_loss: 0.0400\n",
      "Epoch 4/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.0328 - val_loss: 0.0438\n",
      "Epoch 5/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.0311 - val_loss: 0.0395\n",
      "Epoch 6/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 0.0290 - val_loss: 0.0338\n",
      "Epoch 7/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.0285 - val_loss: 0.0404\n",
      "Epoch 8/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0276 - val_loss: 0.0356\n",
      "Epoch 9/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.0269 - val_loss: 0.0320\n",
      "Epoch 10/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 0.0263 - val_loss: 0.0324\n",
      "Epoch 11/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.0266 - val_loss: 0.0321\n",
      "Epoch 12/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 0.0262 - val_loss: 0.0663\n",
      "Epoch 13/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0261 - val_loss: 0.0364\n",
      "Epoch 14/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0248 - val_loss: 0.0363\n",
      "Epoch 15/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0243 - val_loss: 0.0376\n",
      "Epoch 16/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - loss: 0.0238 - val_loss: 0.0412\n",
      "Epoch 17/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.0245 - val_loss: 0.0362\n",
      "Epoch 18/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 0.0243 - val_loss: 0.0341\n",
      "Epoch 19/50\n",
      "\u001b[1m567/567\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.0240 - val_loss: 0.0399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f47f47d2390>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor=\"val_loss\", patience = 10, restore_best_weights=True) \n",
    "\n",
    "# 그리드 서치 추가\n",
    "\n",
    "model.fit(\n",
    "    [x_train, b_train], \n",
    "    y_train,\n",
    "    validation_data=([x_val, b_val], y_val),\n",
    "    epochs=50,\n",
    "    batch_size=512,\n",
    "    callbacks = [es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e37233ab-693c-4b5a-9837-c84ca992fb60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m247/247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step\n",
      "R2 :  0.9625906783208432\n",
      "adjusted R2 :  0.9625526220424311\n",
      "RMSE :  21.724237939806677\n"
     ]
    }
   ],
   "source": [
    "def adj_r2_score(y_true, y_pred, p=x_train.shape[1]):\n",
    "    return 1-(1-r2_score(y_true, y_pred)) * (len(y_true)-1) / (len(y_true) - p - 1)\n",
    "\n",
    "pred = model.predict([x_test, b_test])\n",
    "pred_ = ss_y.inverse_transform(pred)\n",
    "ad_r2 = adj_r2_score(y_test, pred_)\n",
    "mse = mean_squared_error(y_test, pred_)\n",
    "r2 = r2_score(y_test, pred_)\n",
    "\n",
    "print(\"R2 : \", r2)\n",
    "print(\"adjusted R2 : \", ad_r2)\n",
    "print(\"RMSE : \", np.sqrt(mse))\n",
    "\n",
    "# 기본변수\n",
    "# R2 :  0.9698835280330486\n",
    "# adjusted R2 :  0.9698337107362461\n",
    "# RMSE :  18.884774654730865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1a897fc2-a9bb-4381-a46a-566e5ee315c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('neural_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a3f09-cc57-4ed7-a907-f1de8a844873",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Convolution - Batch Normalization - Activation - Dropout - Pooling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
